{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec494b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import time\n",
    "from gcsfs import GCSFileSystem\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import pyreadstat\n",
    "from typing import Tuple, Optional, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d3c56eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials file is valid.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Place credentials path in a config.py file\n",
    "CREDENTIALS_PATH =  r\"C:\\Users\\eprashar\\AppData\\Roaming\\gcloud\\application_default_credentials.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(CREDENTIALS_PATH)\n",
    "\n",
    "# Verify credentials\n",
    "# TODO: This goes in a utils script later\n",
    "def check_and_authenticate(json_path):\n",
    "    '''\n",
    "    Function to check google authentication token and re-generate if it is expired/doesn't exist\n",
    "    '''\n",
    "    try:\n",
    "        if not os.path.exists(json_path):\n",
    "            raise FileNotFoundError(\"Credentials file not found\")\n",
    "        # Get modification time of the file\n",
    "        file_mod_time = datetime.fromtimestamp(os.path.getmtime(json_path))\n",
    "        current_time = datetime.now()\n",
    "\n",
    "        # Check if the file is older than 24 hours\n",
    "        if current_time - file_mod_time > timedelta(hours=24):\n",
    "            print(\"Credentials file is older than 24 hours. Re-authenticating...\")\n",
    "\n",
    "            # Re-authenticate\n",
    "            try:\n",
    "                print(f\"Trying reauthentication on gcloud server using shell command...\")\n",
    "                subprocess.run(\"start cmd /c gcloud auth application-default login\", shell=True, check=True)\n",
    "                print('Login window opened...please complete authentication')\n",
    "                \n",
    "                # Poll for file modification\n",
    "                print(\"Waiting for credentials file to update...\")\n",
    "                max_wait = 300  # seconds\n",
    "                check_interval = 2  # seconds\n",
    "                start_time = datetime.now()\n",
    "\n",
    "                while (datetime.now() - start_time).total_seconds() < max_wait:\n",
    "                    new_mod_time = datetime.fromtimestamp(os.path.getmtime(json_path))\n",
    "                    if new_mod_time > file_mod_time:\n",
    "                        print(\"Authentication confirmed! Credentials file updated.\")\n",
    "                        break\n",
    "                    time.sleep(check_interval)\n",
    "                else:\n",
    "                    print(\"Timed out waiting for credentials file update.\")\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error during re-authentication: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f'Authentication failed because of {e}')\n",
    "        else:\n",
    "            print(\"Credentials file is valid.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Verify credentials\n",
    "check_and_authenticate(CREDENTIALS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6be17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCS paths\n",
    "# TODO: Transfer these to a config file\n",
    "# Token doesn't need to be provided as long as authentication is done as above\n",
    "# However, it is better to be explicit. Possible ways to define token are here: https://gcsfs.readthedocs.io/en/latest/api.html\n",
    "fs = GCSFileSystem(project='clgx-gis-app-dev-06e3')\n",
    "\n",
    "#Path to GCS buckets\n",
    "gcs_path = \"gs://geospatial-projects/location_inc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc4240a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sav(\n",
    "    local_path: str, \n",
    "    gcs_folder_path: str = \"\", \n",
    "    fs: Optional[Any] = None\n",
    ") -> Tuple[pd.DataFrame, Any]:\n",
    "    \"\"\"\n",
    "    Reads an SPSS .sav file. It prioritizes reading from a local directory; \n",
    "    if the file is not found locally, it attempts to download from GCS using \n",
    "    the provided filesystem object.\n",
    "\n",
    "    Args:\n",
    "        local_path (str): The local path to the .sav file (e.g., \"data/municipalities.sav\").\n",
    "        gcs_folder_path (str): The GCS bucket/folder path (e.g., \"bucket_name/raw_data\").\n",
    "                               Required only if reading from GCS.\n",
    "        fs (Optional[GCSFileSystem]): The GCS FileSystem object. Required only if \n",
    "                                      the file is not found locally.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Any]: A tuple containing the pandas DataFrame and \n",
    "                                  the pyreadstat metadata object.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If file is not local and 'fs' is not provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Construct the expected local path\n",
    "    local_path = os.path.abspath(local_path)\n",
    "\n",
    "    # 2. Check if the file exists locally\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Reading local file from: {local_path}\")\n",
    "        df, meta = pyreadstat.read_sav(local_path)\n",
    "        return df, meta\n",
    "\n",
    "    # 3. If not local, attempt GCS download\n",
    "    print(f\"File not found locally at '{local_path}'. Attempting GCS download...\")\n",
    "\n",
    "    if fs is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"File '{local_path}' not found locally and no GCSFileSystem (fs) was provided.\"\n",
    "        )\n",
    "\n",
    "    # Construct full GCS path (handling potential trailing slashes)\n",
    "    # TODO: Correct this code to handle GCS path construction properly\n",
    "    # filename = os.path.basename(local_path)\n",
    "    # full_gcs_path = os.path.join(gcs_folder_path, filename)\n",
    "\n",
    "    # try:\n",
    "    #     with fs.open(full_gcs_path, \"rb\") as gcs_file:\n",
    "    #         # Write GCS content to a temporary file\n",
    "    #         with tempfile.NamedTemporaryFile(delete=False, suffix=\".sav\") as temp_file:\n",
    "    #             print(f\"Downloading from GCS: {full_gcs_path}\")\n",
    "    #             temp_file.write(gcs_file.read())\n",
    "    #             temp_file.flush()\n",
    "    #             temp_file.close() # Close to ensure pyreadstat can open it safely\n",
    "                \n",
    "    #             # Read the temp file\n",
    "    #             df, meta = pyreadstat.read_sav(temp_file.name)\n",
    "                \n",
    "    #             # Optional: Clean up temp file immediately after read\n",
    "    #             os.unlink(temp_file.name)\n",
    "                \n",
    "    #     return df, meta\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     raise RuntimeError(f\"Failed to read from GCS path '{full_gcs_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13668c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local data path\n",
    "# TODO: If this data is inserted in a sub-folder inside data, that will need to be reflected in the path\n",
    "muni_acs_path = r'C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\2026\\geo similarity teu\\data\\raw\\demographics\\location_inc_demographic_acs_5_2023_muni_acs.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c97a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading local file from: C:\\Users\\eprashar\\OneDrive - CoreLogic Solutions, LLC\\github\\2026\\geo similarity teu\\data\\location_inc_demographic_acs_5_2023_muni_acs.sav\n",
      "Data loaded in 4.65 seconds\n"
     ]
    }
   ],
   "source": [
    "# Read the municipalities ACS data\n",
    "start_time = time.time()\n",
    "muni_acs_df, muni_acs_meta = read_sav(\n",
    "    local_path=muni_acs_path\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f'Data loaded in {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71c0ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geoid', 'NAME', 'STUSAB', 'GEO_ID', 'veteran_pct',\n",
       "       'kids_working_parents_pct', 'kids_u6_working_parents_pct',\n",
       "       'working_parents_hh_pct', 'kids_parent_ratio', 'md_hhinc',\n",
       "       ...\n",
       "       'socc_admin_m', 'mocc_manager_m', 'mocc_prof_m', 'mocc_service_m',\n",
       "       'mocc_farm_m', 'farm_pct_m', 'mocc_constr_m', 'mocc_manu_m',\n",
       "       'mocc_trans_m', 'mocc_sales_m'],\n",
       "      dtype='object', length=635)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine muni_acs columns\n",
    "muni_acs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86bc054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_acs_df.head(1000).to_csv(\"muni_acs_head_1000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3162b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69948 entries, 0 to 69947\n",
      "Columns: 635 entries, geoid to mocc_sales_m\n",
      "dtypes: float64(630), object(5)\n",
      "memory usage: 338.9+ MB\n",
      "None\n",
      "     geoid                      NAME STUSAB            GEO_ID  veteran_pct  \\\n",
      "0    01001   Autauga County, Alabama     AL    0500000US01001     7.811419   \n",
      "1  0100100       Abanda CDP, Alabama     AL  1600000US0100100     0.000000   \n",
      "2  0100124   Abbeville city, Alabama     AL  1600000US0100124     4.412955   \n",
      "3    01003   Baldwin County, Alabama     AL    0500000US01003     8.622809   \n",
      "4  0100460  Adamsville city, Alabama     AL  1600000US0100460     7.527383   \n",
      "\n",
      "   kids_working_parents_pct  kids_u6_working_parents_pct  \\\n",
      "0                 67.373547                    61.585835   \n",
      "1                100.000000                          NaN   \n",
      "2                 64.691358                    66.666667   \n",
      "3                 69.194412                    66.365550   \n",
      "4                 24.843945                    10.933941   \n",
      "\n",
      "   working_parents_hh_pct  kids_parent_ratio  md_hhinc  ...  socc_admin_m  \\\n",
      "0               19.637704        2371.549745   69841.0  ...      0.121105   \n",
      "1               31.578947        6980.609418       NaN  ...      0.571429   \n",
      "2               10.821643         568.366236   32778.0  ...      0.167076   \n",
      "3               15.865049        1619.083599   75019.0  ...      0.103390   \n",
      "4                5.126761         777.324434   60564.0  ...      0.108093   \n",
      "\n",
      "   mocc_manager_m  mocc_prof_m  mocc_service_m  mocc_farm_m  farm_pct_m  \\\n",
      "0        0.151164     0.203662        0.140816     0.003980    0.003980   \n",
      "1        0.000000     0.000000        0.000000     0.000000    0.000000   \n",
      "2        0.041769     0.230958        0.169533     0.000000    0.000000   \n",
      "3        0.147249     0.211809        0.168307     0.002802    0.002802   \n",
      "4        0.098859     0.199891        0.239544     0.000000    0.000000   \n",
      "\n",
      "   mocc_constr_m  mocc_manu_m  mocc_trans_m  mocc_sales_m  \n",
      "0       0.091540     0.080434      0.108066      0.220340  \n",
      "1       0.000000     0.428571      0.000000      0.571429  \n",
      "2       0.094595     0.114251      0.138821      0.210074  \n",
      "3       0.095860     0.064524      0.074273      0.235177  \n",
      "4       0.092884     0.053232      0.135796      0.179794  \n",
      "\n",
      "[5 rows x 635 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the municipalities ACS data\n",
    "print(muni_acs_df.info())\n",
    "#print(muni_acs_df.dtypes)\n",
    "print(muni_acs_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine municipalities ACS metadata\n",
    "# Throws TypeError: Object of type datetime is not JSON serializable when serializing dict item 'creation_time'\n",
    "# TODO: Handle datetime serialization for JSON \n",
    "# json.dump(muni_acs_meta.__dict__, open(\"muni_acs_metadata.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c1592a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STUSAB  count_municipalities_places  count_townships_county_subdivisions\n",
      "0                                    0                                    0\n",
      "1      AK                          355                                   37\n",
      "2      AL                          593                                  390\n",
      "3      AR                          625                                 1095\n",
      "4      AZ                          467                                   80\n",
      "5      CA                         1618                                  404\n",
      "6      CO                          482                                  209\n",
      "7      CT                          215                                  170\n",
      "8      DC                            0                                    1\n",
      "9      DE                           79                                   27\n",
      "10     FL                          955                                  316\n",
      "11     GA                          675                                  586\n",
      "12     HI                          163                                   44\n",
      "13     IA                         1026                                 1660\n",
      "14     ID                          236                                  170\n",
      "15     IL                         1457                                 1694\n",
      "16     IN                          972                                 1011\n",
      "17     KS                          620                                 1521\n",
      "18     KY                          554                                  493\n",
      "19     LA                          489                                  576\n",
      "20     MA                          190                                  352\n",
      "21     MD                          536                                  290\n",
      "22     ME                          132                                  528\n",
      "23     MI                          465                                 1521\n",
      "24     MN                           64                                 2710\n",
      "25     MO                         1081                                 1394\n",
      "26     MS                          427                                  410\n",
      "27     MT                          497                                  194\n",
      "28     NC                          777                                 1041\n",
      "29     ND                           51                                 1755\n",
      "30     NE                          563                                 1189\n",
      "31     NH                           87                                  260\n",
      "32     NJ                          377                                  565\n",
      "33     NM                          527                                  130\n",
      "34     NV                          133                                   71\n",
      "35     NY                         1232                                 1009\n",
      "36     OH                         1008                                 1579\n",
      "37     OK                          846                                  305\n",
      "38     OR                          426                                  212\n",
      "39     PA                          989                                 2561\n",
      "40     PR                          292                                  902\n",
      "41     RI                           28                                   40\n",
      "42     SC                          475                                  299\n",
      "43     SD                          175                                 1318\n",
      "44     TN                          504                                  844\n",
      "45     TX                         1863                                  862\n",
      "46     UT                          334                                   93\n",
      "47     VA                          688                                  552\n",
      "48     VT                          169                                  256\n",
      "49     WA                          639                                  242\n",
      "50     WI                          202                                 1851\n",
      "51     WV                          439                                  226\n",
      "52     WY                          205                                   71\n"
     ]
    }
   ],
   "source": [
    "# For each state (STUSAB), check split between GEO_ID starting with 1600 (municipalities) and 060 (Townships)\n",
    "# In the printed table, have 3 columns: state, count of municipalities and count of townships\n",
    "# We use a simple function to tag each row based on how GEO_ID starts\n",
    "def classify_geo(geo_id):\n",
    "    if str(geo_id).startswith('1600'):\n",
    "        return 'Place_Municipality'\n",
    "    elif str(geo_id).startswith('060'):\n",
    "        return 'Township_County_SubDivision'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the classification\n",
    "muni_acs_df['Type'] = muni_acs_df['GEO_ID'].apply(classify_geo)\n",
    "\n",
    "# 2. Group by State and Type, then reshape\n",
    "# - groupby: counts occurrences of each Type per State\n",
    "# - unstack: pivots 'Type' from rows to columns\n",
    "# - fillna(0): replaces NaN with 0 for states that might lack one type\n",
    "summary = (\n",
    "    muni_acs_df.groupby(['STUSAB', 'Type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    [['Place_Municipality', 'Township_County_SubDivision']] # Select only the columns we want\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename columns for the final clean output\n",
    "summary.columns.name = None # Remove the index name 'Type'\n",
    "summary = summary.rename(columns={\n",
    "    'Place_Municipality': 'count_municipalities_places',\n",
    "    'Township_County_SubDivision': 'count_townships_county_subdivisions'\n",
    "})\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Strong MCD\" states where we want to include Townships (SumLev 060)\n",
    "# CT, MA, ME, MI, MN, NH, NJ, NY, PA, RI, VT, WI\n",
    "STRONG_MCD_STATES = [\n",
    "    \"09\", \"25\", \"23\", \"26\", \"27\", \"33\", \n",
    "    \"34\", \"36\", \"42\", \"44\", \"50\", \"55\"\n",
    "]\n",
    "\n",
    "# Column mapping for consistent ID handling\n",
    "GEO_ID_COL_ACS = \"GEO_ID\"      # Usually '1600000US0100100'\n",
    "GEO_ID_COL_SHP = \"GEOID\"       # Usually '0100100'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_select_teu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
